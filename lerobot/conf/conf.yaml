model:
  vision:
    channels: [8, 16]
    kernels: [6, 6, 6]
    strides: [3, 3, 3]
    paddings: [3, 3, 3]
    #パディングしないほうがいい
  
  mlp:
    mlp_hidden_dim: 256
    n_mlp_layers: 0  #MLPの隠れ層の数

  policy:
    hidden_dim: 256 #RNNの隠れ層の次元
    robot_state_feature_dim: 6
    vision_encoder_output_dim: 64
  
  latent_obs_dim: 64 #潜在変数の次元(obs=観測情報)

  diffusion:
    n_obs_steps: 2 #何ステップ過去として入れるか3
    horizon: 16 #未来のステップ数
    n_action_steps: 6 #実際に行動するステップ数10

data:
  split_ratio: [0.7, 0.2, 0.1]
  batch_size: 10
  seed: 0

train:
  learning_rate: 0.001
  weight_decay: 1.0e-6
  epoch: 500


logging:
  best_epoch_path: result/diffusion3/model/best_epoch.yaml

wandb:
  project_name: 'Kensyu_3_new'
  train_name: 'diffusion3'
  config:
    device: 'cuda:0'

run:
  steps: 50
  fps: 5

diffuser:
  num_timesteps: 100 #Diffusionのステップ数
  beta_start: 0.0001 #Diffusionのbetaの開始値
  beta_end: 0.02 #Diffusionのbetaの終了値
  beta_schedule: 'linear' #Diffusionのbetaのスケジュール
  clip_sample: True #Diffusionのサンプルをクリップするか
  prediction_type: 'epsilon' #Diffusionの予測タイプ
  name: DDIM

